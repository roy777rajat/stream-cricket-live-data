{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d511016",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, from_json, when, size, explode, max as Fmax, year, month, dayofmonth\n",
    "from pyspark.sql.types import StructType, StructField, StringType, BooleanType, ArrayType, IntegerType, FloatType, TimestampType\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "45144195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON schema for parsed JSON in raw data\n",
    "json_schema = StructType([\n",
    "    StructField(\"status\", StringType()),\n",
    "    StructField(\"venue\", StringType()),\n",
    "    StructField(\"date\", StringType()),\n",
    "    StructField(\"dateTimeGMT\", StringType()),\n",
    "    StructField(\"teams\", ArrayType(StringType())),\n",
    "    StructField(\"teamInfo\", ArrayType(\n",
    "        StructType([\n",
    "            StructField(\"name\", StringType()),\n",
    "            StructField(\"img\", StringType())\n",
    "        ])\n",
    "    )),\n",
    "    StructField(\"score\", ArrayType(\n",
    "        StructType([\n",
    "            StructField(\"r\", IntegerType()),\n",
    "            StructField(\"w\", IntegerType()),\n",
    "            StructField(\"o\", FloatType()),\n",
    "            StructField(\"inning\", StringType())\n",
    "        ])\n",
    "    )),\n",
    "    StructField(\"series_id\", StringType()),\n",
    "    StructField(\"fantasyEnabled\", BooleanType()),\n",
    "    StructField(\"bbbEnabled\", BooleanType()),\n",
    "    StructField(\"hasSquad\", BooleanType()),\n",
    "    StructField(\"matchStarted\", BooleanType()),\n",
    "    StructField(\"matchEnded\", BooleanType())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7130b6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "target_path = \"s3a://aws-glue-assets-cricket/output_cricket/live/score_data\"\n",
    "base_static_path = \"s3a://aws-glue-assets-cricket/output_cricket/live/cricket_data\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "25d3899f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load static metadata for today's partition\n",
    "def load_static_match_data(spark):\n",
    "    today = datetime.utcnow().date()\n",
    "    path = f\"{base_static_path}/year={today.year}/month={today.month}/day={today.day}\"\n",
    "    static_df = spark.read.option(\"basePath\", base_static_path).parquet(path)\n",
    "    static_df = static_df.dropDuplicates([\"id\"])\n",
    "    return static_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0073dbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_process():\n",
    "    spark = SparkSession.builder.getOrCreate()\n",
    "    \n",
    "    today = datetime.utcnow()\n",
    "    s3_path = f\"s3a://aws-glue-assets-cricket/raw_cricket_data/year={today.year}/month={today.month:02}/day={today.day:02}/*/*/\"\n",
    "    \n",
    "    raw_schema = StructType([\n",
    "        StructField(\"id\", StringType(), True),\n",
    "        StructField(\"name\", StringType(), True),\n",
    "        StructField(\"matchType\", StringType(), True),\n",
    "        StructField(\"event_time\", TimestampType(), True),\n",
    "        StructField(\"ingested_at\", StringType(), True),\n",
    "        StructField(\"json_data\", StringType(), True)\n",
    "    ])\n",
    "    \n",
    "    # Read raw parquet batch\n",
    "    raw_df = spark.read.schema(raw_schema).parquet(s3_path)\n",
    "    \n",
    "    static_df = load_static_match_data(spark)\n",
    "\n",
    "    conflicting_cols = [\"matchType\", \"name\", \"match_status\", \"venue\"]\n",
    "    for c in conflicting_cols:\n",
    "        if c in static_df.columns:\n",
    "            static_df = static_df.drop(c)\n",
    "    static_df = static_df.withColumnRenamed(\"id\", \"match_id\")\n",
    "\n",
    "    parsed_df = raw_df.withColumn(\"json_parsed\", from_json(col(\"json_data\"), json_schema))\n",
    "\n",
    "    flat_df = parsed_df.select(\n",
    "        \"id\", \"name\", \"matchType\", \"event_time\",\n",
    "        col(\"json_parsed.status\").alias(\"status\"),\n",
    "        col(\"json_parsed.venue\").alias(\"venue\"),\n",
    "        col(\"json_parsed.teams\").alias(\"teams\"),\n",
    "        col(\"json_parsed.score\").alias(\"score\"),\n",
    "        col(\"json_parsed.matchStarted\").alias(\"matchStarted\"),\n",
    "        col(\"json_parsed.matchEnded\").alias(\"matchEnded\")\n",
    "    ).withColumn(\"event_time_ts\", col(\"event_time\").cast(\"timestamp\"))\n",
    "\n",
    "    max_times = flat_df.groupBy(\"id\").agg(Fmax(\"event_time_ts\").alias(\"max_ts\")) \\\n",
    "                       .withColumnRenamed(\"id\", \"max_id\")\n",
    "\n",
    "    latest_df = flat_df.join(\n",
    "        max_times,\n",
    "        (flat_df.id == max_times.max_id) & (flat_df.event_time_ts == max_times.max_ts),\n",
    "        \"inner\"\n",
    "    ).drop(\"max_id\", \"max_ts\")\n",
    "\n",
    "    latest_df = latest_df.withColumn(\n",
    "        \"match_status\",\n",
    "        when((col(\"matchStarted\") == True) & (col(\"matchEnded\") == False) & (size(col(\"score\")) > 0), \"Live\")\n",
    "        .when((col(\"matchStarted\") == True) & (col(\"matchEnded\") == False), \"Upcoming\")\n",
    "        .when(col(\"matchEnded\") == True, \"Completed\")\n",
    "        .otherwise(\"Unknown\")\n",
    "    )\n",
    "\n",
    "    live_df = latest_df.filter(col(\"match_status\") == \"Live\")\n",
    "\n",
    "    exploded_df = live_df.select(\n",
    "        \"id\", \"name\", \"matchType\", \"event_time_ts\", \"status\", \"venue\", \"teams\", \"match_status\",\n",
    "        explode(col(\"score\")).alias(\"score_entry\")\n",
    "    )\n",
    "    print(f\"Raw Count: {exploded_df.count()}\")\n",
    "    final_df = exploded_df.select(\n",
    "        col(\"id\").alias(\"match_id\"),\n",
    "        \"name\",\n",
    "        \"matchType\",\n",
    "        \"event_time_ts\",\n",
    "        \"status\",\n",
    "        \"venue\",\n",
    "        \"teams\",\n",
    "        \"match_status\",\n",
    "        col(\"score_entry.inning\").alias(\"inning\"),\n",
    "        col(\"score_entry.r\").alias(\"runs\"),\n",
    "        col(\"score_entry.w\").alias(\"wickets\"),\n",
    "        col(\"score_entry.o\").alias(\"overs\")\n",
    "    )\n",
    "\n",
    "    print(f\"Rows before join: {final_df.count()}\")\n",
    "\n",
    "    enriched_df = final_df.join(static_df, on=\"match_id\", how=\"left\")\n",
    "    print(f\"Rows after join: {enriched_df.count()}\")\n",
    "\n",
    "    # Add partition columns before writing\n",
    "    enriched_df = enriched_df.withColumn(\"year\", year(\"event_time_ts\")) \\\n",
    "                             .withColumn(\"month\", month(\"event_time_ts\")) \\\n",
    "                             .withColumn(\"day\", dayofmonth(\"event_time_ts\"))\n",
    "\n",
    "    # Overwrite only today's partition (best practice to avoid deleting other days)\n",
    "    enriched_df.filter(\n",
    "        (col(\"year\") == today.year) & \n",
    "        (col(\"month\") == today.month) & \n",
    "        (col(\"day\") == today.day)\n",
    "    ).write \\\n",
    "     .partitionBy(\"year\", \"month\", \"day\") \\\n",
    "     .mode(\"overwrite\") \\\n",
    "     .parquet(target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9ba95a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Count: 9\n",
      "Rows before join: 9\n",
      "Rows after join: 9\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    from pyspark.sql import SparkSession\n",
    "    batch_process()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
